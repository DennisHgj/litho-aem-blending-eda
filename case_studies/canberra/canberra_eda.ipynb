{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Downloading the data \n",
    "\n",
    "### Elevation\n",
    "\n",
    "TODO adapt from swan coastal\n",
    "\n",
    "```bash\n",
    "mkdir -p $HOME/data/Lithology/swan_coastal\n",
    "cd $HOME/data/Lithology/swan_coastal\n",
    "curl -o Swan_DEM.7z https://cloudstor.aarnet.edu.au/plus/s/HL3h7u67xUA1ilR/download\n",
    "7za x Swan_DEM.7z\n",
    "```\n",
    "\n",
    "Windows:\n",
    "\n",
    "```bat\n",
    "mkdir -p c:\\data\\Lithology\\swan_coastal\n",
    "cd c:\\data\\Lithology\\swan_coastal\n",
    "curl -o Swan_DEM.7z https://cloudstor.aarnet.edu.au/plus/s/HL3h7u67xUA1ilR/download\n",
    "7z x Swan_DEM.7z\n",
    "```\n",
    "\n",
    "### Borehole logs\n",
    "\n",
    "TODO adapt from swan coastal\n",
    "\n",
    "```bash\n",
    "mkdir -p $HOME/data/Lithology/\n",
    "cd $HOME/data/Lithology/\n",
    "curl -o NGIS_SCP.7z https://cloudstor.aarnet.edu.au/plus/s/KLEBWonjOAOPVVd/download\n",
    "7za x NGIS_SCP.7z\n",
    "```\n",
    "\n",
    "Windows:\n",
    "\n",
    "```bat\n",
    "cd c:\\data\\Lithology\n",
    "curl -o NGIS_SCP.7z https://cloudstor.aarnet.edu.au/plus/s/KLEBWonjOAOPVVd/download\n",
    "7z x NGIS_SCP.7z\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:54:38.357642Z",
     "start_time": "2018-02-27T01:54:36.460827Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only set to True for co-dev of ela from this use case:\n",
    "ela_from_source = False\n",
    "ela_from_source = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ela_from_source:\n",
    "    if ('ELA_SRC' in os.environ):\n",
    "        root_src_dir = os.environ['ELA_SRC']\n",
    "    elif sys.platform == 'win32':\n",
    "        root_src_dir = r'C:\\src\\github_jm\\pyela'\n",
    "    else:\n",
    "        username = os.environ['USER']\n",
    "        root_src_dir = os.path.join('/home', username, 'src/ela/pyela')\n",
    "    pkg_src_dir = root_src_dir\n",
    "    sys.path.insert(0, pkg_src_dir)\n",
    "\n",
    "from ela.textproc import *\n",
    "from ela.utils import *\n",
    "from ela.classification import *\n",
    "from ela.visual import *\n",
    "from ela.spatial import SliceOperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "\n",
    "There are two main sets of information we need: the borehole lithology logs, and the spatial information in the surface elevation (DEM) and geolocation of a subset of bores around Bungendore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably want to explicitly set `data_path` to the location where you put the folder(s) e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = '/home/myusername/data' # On Linux, if you now have the folder /home/myusername/data/Bungendore\n",
    "#data_path = r'C:\\data\\Lithology'  # windows, if you have C:\\data\\Lithology\\Bungendore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise a fallback for the pyela developer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_path is None:\n",
    "    if ('ELA_DATA' in os.environ):\n",
    "        data_path = os.environ['ELA_DATA']\n",
    "    elif sys.platform == 'win32':\n",
    "        data_path = r'C:\\data\\Lithology'\n",
    "    else:\n",
    "        username = os.environ['USER']\n",
    "        data_path = os.path.join('/home', username, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aem_datadir = os.path.join(data_path, 'AEM')\n",
    "cbr_datadir = os.path.join(data_path, 'Canberra')\n",
    "cbr_datadir_out = os.path.join(cbr_datadir, 'out')\n",
    "# scp_datadir = os.path.join(aem_datadir, 'Swan_coastal_plains')\n",
    "# scp_grids_datadir = os.path.join(scp_datadir, 'grids')\n",
    "ngis_datadir = os.path.join(data_path, 'NGIS')\n",
    "act_shp_datadir = os.path.join(ngis_datadir, 'shp_ACT')\n",
    "bidgee_shp_datadir = os.path.join(ngis_datadir, 'shp_murrumbidgee_river')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = rasterio.open(os.path.join(cbr_datadir,'CLIP.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "show(dem,title='Canberra', cmap='terrain',  ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bore_locations_raw = gpd.read_file(os.path.join(cbr_datadir, 'Bores/act_bores.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bore_locations_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bore_locations_raw.crs, dem.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DEM raster and the bore location shapefile do not use the same projection (coordinate reference system) so we reproject one of them. We choose the raster's UTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bore_locations = bore_locations_raw.to_crs(dem.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_logs_act = pd.read_csv(os.path.join(act_shp_datadir, 'NGIS_LithologyLog.csv'))\n",
    "lithology_logs_bidgee = pd.read_csv(os.path.join(bidgee_shp_datadir, 'NGIS_LithologyLog.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lithology_logs_act), len(lithology_logs_bidgee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_logs = pd.concat([lithology_logs_act, lithology_logs_bidgee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "show(dem,title='Swan Coastal Plain', cmap='terrain',  ax=ax)\n",
    "bore_locations.plot(ax=ax, facecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to the location of interest\n",
    "\n",
    "The lithology logs are for all of western australia, which is much larger than the area of interest and for which we have the geolocation of boreholes. We subset to the location of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:36.439052Z",
     "start_time": "2018-02-06T00:50:36.434305Z"
    }
   },
   "outputs": [],
   "source": [
    "df = lithology_logs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's subset the logs based on spatial locations, to keep only those \"nearby\" the DEM we have near the locality of Bungendore in this case study. First define a few constants: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_FROM_COL = 'FromDepth'\n",
    "DEPTH_TO_COL = 'ToDepth'\n",
    "\n",
    "TOP_ELEV_COL = 'TopElev'\n",
    "BOTTOM_ELEV_COL = 'BottomElev'\n",
    "\n",
    "LITHO_DESC_COL = 'Description'\n",
    "HYDRO_CODE_COL = 'HydroCode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the geolocation from the shapefile and lithology records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geopandas data frame has a column geometry listing `POINT` objects. 'ela' includes  `get_coords_from_gpd_shape` to extrace the coordinates to a simpler structure. 'ela' has predefined column names (e.g. EASTING_COL) defined for easting/northing information, that we can use to name our coordinate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bore_locations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoloc = get_coords_from_gpd_shape(bore_locations, colname='geometry', out_colnames=[EASTING_COL, NORTHING_COL])\n",
    "geoloc[HYDRO_CODE_COL] = bore_locations[HYDRO_CODE_COL]\n",
    "# We keep lat/long for potential leaflet viewer\n",
    "geoloc['Latitude'] = bore_locations['Latitude']\n",
    "geoloc['Longitude'] = bore_locations['Longitude']\n",
    "geoloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data frame we can perform two operations in one go: subsetting the lithology records to only the 640 bores of interest, and adding to the result the x/y geolocations to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geoloc), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoloc[HYDRO_CODE_COL].dtype, df[HYDRO_CODE_COL].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geoloc[HYDRO_CODE_COL] = geoloc[HYDRO_CODE_COL].apply(parse_int)\n",
    "# df[HYDRO_CODE_COL] = df[HYDRO_CODE_COL].apply(parse_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, geoloc, how='inner', on=HYDRO_CODE_COL, sort=False, copy=True, indicator=False, validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round up 'depth to' and 'depth from' columns\n",
    "\n",
    "We round the depth related columns to the upper integer value and drop the entries where the resulting depths have degenerated to 0. `ela` has a class `DepthsRounding` to facilitate this operations on lithology records with varying column names.\n",
    "\n",
    "We first clean up height/depths columns to make sure they are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_numeric(x):\n",
    "    if isinstance(x, float):\n",
    "        return x\n",
    "    if x == 'None':\n",
    "        return np.nan\n",
    "    elif x is None:\n",
    "        return np.nan\n",
    "    elif isinstance(x, str):\n",
    "        return float(x)\n",
    "    else:\n",
    "        return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[DEPTH_FROM_COL] = df[DEPTH_FROM_COL].apply(as_numeric)\n",
    "df[DEPTH_TO_COL] = df[DEPTH_TO_COL].apply(as_numeric)\n",
    "df[TOP_ELEV_COL] = df[TOP_ELEV_COL].apply(as_numeric)\n",
    "df[BOTTOM_ELEV_COL] = df[BOTTOM_ELEV_COL].apply(as_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DepthsRounding(DEPTH_FROM_COL, DEPTH_TO_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Before rounding heights we have \" + str(len(df)) + \" records\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dr.round_to_metre_depths(df, np.round, True)\n",
    "\"After removing thin sliced entries of less than a metre, we are left with \" + str(len(df)) + \" records left\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the descriptive lithology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = df[LITHO_DESC_COL]\n",
    "descs = descs.reset_index()\n",
    "descs = descs[LITHO_DESC_COL]\n",
    "descs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description column as read seems to be objects. Other columns seem to be objects when they should be numeric. We define two functions to clean these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_desc(x):\n",
    "    if isinstance(x, float):\n",
    "        return u''\n",
    "    elif x is None:\n",
    "        return u''\n",
    "    else:\n",
    "        # python2 return unicode(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [clean_desc(x) for x in descs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from striplog import Lexicon\n",
    "lex = Lexicon.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clean_lithology_descriptions(y, lex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a flat list of all the \"tokens\" but remove stop words ('s', 'the' and the like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = v_lower(y)\n",
    "vt = v_word_tokenize(y)\n",
    "flat = np.concatenate(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "exclude = stoplist + ['.',',',';',':','(',')','-']\n",
    "flat = [word for word in flat if word not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common= token_freq(flat, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(df_most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining lithology classes and finding primary/secondary lithologies\n",
    "\n",
    "From the list of most common tokens, we may want to define lithology classes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[LITHO_DESC_COL] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies = ['shale', 'clay','granite','soil','sand', 'porphyry','siltstone','gravel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for visualisation\n",
    "lithology_color_names = ['lightslategrey', 'olive', 'dimgray', 'chocolate',  'gold',     'tomato', 'teal', 'lavender']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to capture any of these we devise a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lithologies_numclasses = create_numeric_classes(lithologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies_dict = dict([(x,x) for x in lithologies])\n",
    "lithologies_dict['dacite'] = 'granite'\n",
    "lithologies_dict['sandstone'] = 'granite'\n",
    "lithologies_dict['slate'] = 'granite'\n",
    "lithologies_dict['rock'] = 'granite'\n",
    "lithologies_dict['ryodacite'] = 'granite'\n",
    "lithologies_dict['mudstone'] = 'sand' # ??\n",
    "lithologies_dict['topsoil'] = 'soil' # ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_litho_markers_re = r'shale|clay|granit|soil|sand|porphy|silt|gravel|dacit|slat|rock|stone'\n",
    "regex = re.compile(any_litho_markers_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies_adjective_dict = {\n",
    "    'sandy' :  'sand',\n",
    "    'clayey' :  'clay',\n",
    "    'clayish' :  'clay',\n",
    "    'shaley' :  'shale',\n",
    "    'silty' :  'silt',\n",
    "    'pebbly' :  'pebble',\n",
    "    'gravelly' :  'gravel',\n",
    "    'porphyritic': 'porphyry'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tokens = v_word_tokenize(y)\n",
    "litho_terms_detected = v_find_litho_markers(v_tokens, regex=regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we detect these lithology markers in each bore log entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mark = [x for x in litho_terms_detected if len(x) == 0 ]\n",
    "at_least_one_mark = [x for x in litho_terms_detected if len(x) >= 1]\n",
    "at_least_two_mark = [x for x in litho_terms_detected if len(x) >= 2]\n",
    "print('There are %s entries with no marker, %s entries with at least one, %s with at least two'%(len(zero_mark),len(at_least_one_mark),len(at_least_two_mark)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: probably need to think of precanned facilities in ela to assess the detection rate in such EDA. Maybe wordcloud not such a bad idea too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_zero_mark = [y[i] for i in range(len(litho_terms_detected)) if len(litho_terms_detected[i]) == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(descs_zero_mark,20)\n",
    "# descs_zero_mark[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_litho = v_find_primary_lithology(litho_terms_detected, lithologies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_litho = v_find_secondary_lithology(litho_terms_detected, primary_litho, lithologies_adjective_dict, lithologies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[PRIMARY_LITHO_COL]=primary_litho\n",
    "df[SECONDARY_LITHO_COL]=secondary_litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[PRIMARY_LITHO_NUM_COL] = v_to_litho_class_num(primary_litho, my_lithologies_numclasses)\n",
    "df[SECONDARY_LITHO_NUM_COL] = v_to_litho_class_num(secondary_litho, my_lithologies_numclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting depth below ground to Australian Height Datum elevation\n",
    "\n",
    "While the bore entries have columns for AHD elevations, many appear to be missing data. Since we have a DEM of the region we can correct this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = HeightDatumConverter(dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cd.add_height(df, \n",
    "        depth_from_col=DEPTH_FROM_COL, depth_to_col=DEPTH_TO_COL, \n",
    "        depth_from_ahd_col=DEPTH_FROM_AHD_COL, depth_to_ahd_col=DEPTH_TO_AHD_COL, \n",
    "        easting_col=EASTING_COL, northing_col=NORTHING_COL, drop_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be reused in experimental notebooks:\n",
    "classified_logs_filename = os.path.join(cbr_datadir_out,'classified_logs.pkl')\n",
    "if not os.path.exists(classified_logs_filename):\n",
    "    df.to_pickle(classified_logs_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewer\n",
    "\n",
    "Derived from [voila-gpx-viewer](https://github.com/jtpio/voila-gpx-viewer) and [ipyleaflet docs](https://ipyleaflet.readthedocs.io/en/latest/api_reference/popup.html)\n",
    "\n",
    "However this is very difficult to adapt, actually use case is quite different from the GPX data. ipyleaflet doc is sparse and how to I guess the content of callbacks??\n",
    "https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "from io import StringIO\n",
    "#from statistics import mean\n",
    "\n",
    "from bqplot import Axis, Figure, Lines, LinearScale, LogScale\n",
    "from bqplot.interacts import IndexSelector\n",
    "from ipyleaflet import basemaps, FullScreenControl, LayerGroup, Map, MeasureControl, Polyline, Marker, CircleMarker, WidgetControl, MarkerCluster\n",
    "from ipywidgets import Button, HTML, HBox, VBox, Checkbox, FileUpload, Label, Output, IntSlider, Layout, Image, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalThing:\n",
    "    def __init__(self):\n",
    "        self.marker_info = dict()\n",
    "    \n",
    "    def add_marker_info(self, lat, lon, code):\n",
    "        self.marker_info[(lat, lon)] = code\n",
    "    \n",
    "    def get_code(self, lat, lon):\n",
    "        return self.marker_info[(lat, lon)]\n",
    "    \n",
    "globalthing = GlobalThing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Output(layout={'border': '1px solid black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boo():\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        print(\"Boo\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_hydrocode(code):\n",
    "    return df.loc[df['HydroCode'] == code]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(geoloc):\n",
    "    \"\"\"\n",
    "    Plot the GPS trace on a map\n",
    "    \"\"\"\n",
    "    mean_lat = geoloc.Latitude.mean()\n",
    "    mean_lng = geoloc.Longitude.mean()\n",
    "    # create the map\n",
    "    m = Map(center=(mean_lat, mean_lng), zoom=11, basemap=basemaps.Stamen.Terrain)\n",
    "    # show trace\n",
    "    markers = []\n",
    "    def click_handler(**kwargs):\n",
    "        blah = dict(**kwargs)\n",
    "        xy = blah['coordinates']\n",
    "        code = globalthing.get_code(xy[0], xy[1])\n",
    "        bore_data = df.loc[df['HydroCode'] == code]\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            print(code)        \n",
    "            print(bore_data)\n",
    "    for index, row in geoloc.iterrows():\n",
    "        message = HTML()\n",
    "        hc = str(row.HydroCode)\n",
    "        d = data_for_hydrocode(hc)\n",
    "        message.value = \"HydroCode %s has %s records\"%(hc,len(d))\n",
    "        message.placeholder = \"Placeholder\"\n",
    "        message.description = \"Description\"\n",
    "        globalthing.add_marker_info(row.Latitude, row.Longitude, row.HydroCode)\n",
    "        marker = Marker(location=(row.Latitude, row.Longitude))\n",
    "        marker.on_click(click_handler)\n",
    "        #marker.popup = message\n",
    "        markers.append(marker)\n",
    "    marker_cluster = MarkerCluster(\n",
    "        markers=markers\n",
    "    )\n",
    "    #marker_cluster.on_click(click_handler)\n",
    "    m.add_layer(marker_cluster);\n",
    "    m.add_control(FullScreenControl())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(geoloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globalthing.marker_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_handler(coordinates = [-35.33895682, 149.26627207])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Interpolate over a regular grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "# max/min bounds\n",
    "shp_bbox = get_bbox(bore_locations)\n",
    "shp_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_bbox = dem.bounds\n",
    "raster_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = max(shp_bbox[0], raster_bbox[0])\n",
    "x_max = min(shp_bbox[2], raster_bbox[2])\n",
    "y_min = max(shp_bbox[1], raster_bbox[1])\n",
    "y_max = min(shp_bbox[3], raster_bbox[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_res = 200\n",
    "m = create_meshgrid_cartesian(x_min, x_max, y_min, y_max, grid_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array = surface_array(dem, x_min, y_min, x_max, y_max, grid_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array[dem_array <= 0.0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "plt.imshow(to_carto(dem_array), cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array_data = {'bounds': (x_min, x_max, y_min, y_max), 'grid_res': grid_res, 'mesh_xy': m, 'dem_array': dem_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fp = os.path.join(cbr_datadir_out, 'dem_array_data.pkl')\n",
    "if not os.path.exists(fp):\n",
    "    with open(fp, 'wb') as handle:\n",
    "        pickle.dump(dem_array_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define min and max heights on the Z axis for which we interoplate. We use the KNN algorithm with 10 neighbours. We should use a domain such that there are enough points for each height. Let's find visually heights with at least 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=100\n",
    "p = df.hist(column=[DEPTH_FROM_AHD_COL,DEPTH_TO_AHD_COL], sharex=True, sharey=True, bins=n_bins, figsize=(15,5))\n",
    "for axes in p:\n",
    "    axes[0].set_yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours=10\n",
    "ahd_min=530\n",
    "ahd_max=710\n",
    "\n",
    "z_ahd_coords = np.arange(ahd_min,ahd_max,1)\n",
    "dim_x,dim_y = m[0].shape\n",
    "dim_z = len(z_ahd_coords)\n",
    "dims = (dim_x,dim_y,dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_3d_array=np.empty(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GridInterpolation(easting_col=EASTING_COL, northing_col=NORTHING_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.interpolate_volume(lithology_3d_array, df, PRIMARY_LITHO_NUM_COL, z_ahd_coords, n_neighbours, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn DEM into grid\n",
    "z_index_for_ahd = z_index_for_ahd_functor(b=-ahd_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_array.shape, m[0].shape, lithology_3d_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_volume(lithology_3d_array, dem_array, z_index_for_ahd, below=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be reused in experimental notebooks:\n",
    "interp_litho_filename = os.path.join(cbr_datadir_out,'3d_primary_litho.pkl')\n",
    "if not os.path.exists(interp_litho_filename):\n",
    "    with open(interp_litho_filename, 'wb') as handle:\n",
    "        pickle.dump(lithology_3d_array, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_cmap = discrete_classes_colormap(lithology_color_names) # Later for exporting to RGB geotiffs??\n",
    "litho_legend_display_info = [(lithology_cmap[i], lithologies[i], lithology_color_names[i]) for i in range(len(lithologies))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_legend = legend_fig(litho_legend_display_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = cartopy_color_settings(lithology_color_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "imgplot = plt.imshow(to_carto(lithology_3d_array[:, :, z_index_for_ahd(540)]), cmap=cms['cmap'])\n",
    "title = plt.title('Primary litho at +540mAHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ela.visual3d import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = dem_array_data['mesh_xy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_litho = LithologiesClassesVisual3d(lithologies, lithology_color_names, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: problematic with this data - investigate\n",
    "# vis_litho.render_classes_planar(lithology_3d_array, 'Primary lithology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_litho.render_class(lithology_3d_array, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ela has facilities to visualise overlaid information: DEM, classified bore logs, and volumes of interpolated lithologies. This is important to convey .\n",
    "\n",
    "First a bit of data filling for visual purposes, as NaN lithology class codes may cause issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infilled = df.fillna({PRIMARY_LITHO_NUM_COL: -1.0})\n",
    "df_infilled = df_infilled[(df_infilled[DEPTH_TO_AHD_COL] > (ahd_min-20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A factor to apply to Z coordinates, otherwise things would be squashed visually along the heights.\n",
    "# Would prefer a visual only scaling factor, but could not find a way to do so. \n",
    "Z_SCALING = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_coords = np.arange(ahd_min,ahd_max,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_vis_litho = LithologiesClassesOverlayVisual3d(lithologies, lithology_color_names, 'black', dem_array_data, z_coords, Z_SCALING, df_infilled, PRIMARY_LITHO_NUM_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_class(value):\n",
    "    f = overlay_vis_litho.view_overlay(value, lithology_3d_array)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3D Interpolated overlay primary lithology quartz](img/snapshot_quartz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:53:52.073116Z",
     "start_time": "2018-02-06T00:53:50.984843Z"
    }
   },
   "outputs": [],
   "source": [
    "vis_litho = LithologiesClassesVisual3d(lithologies, lithology_color_names, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:53:52.073116Z",
     "start_time": "2018-02-06T00:53:50.984843Z"
    }
   },
   "outputs": [],
   "source": [
    "vis_litho.render_classes_planar(lithology_3d_array, 'Primary lithology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export volumes for depth from ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 100\n",
    "dim_x,dim_y = (lithology_3d_array.shape[0],lithology_3d_array.shape[1])\n",
    "dim_z = max_depth + 1\n",
    "dims = (dim_x,dim_y,dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:52:09.948084Z",
     "start_time": "2018-02-06T00:52:09.942527Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_res = dem_array_data['grid_res']\n",
    "x_min, x_max, y_min, y_max = dem_array_data['bounds']\n",
    "xx, yy = dem_array_data['mesh_xy']\n",
    "dem_array = dem_array_data['dem_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_classes_depth=np.empty(dims)\n",
    "for depth in range(0, dim_z, 1):\n",
    "    s = slice_volume(lithology_3d_array, dem_array - depth, z_index_for_ahd)\n",
    "    litho_classes_depth[:,:,(max_depth - depth)] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "imgplot = plt.imshow(to_carto(litho_classes_depth[:,:,dim_z-30]), cmap=cms['cmap'])\n",
    "t = plt.title('Primary lithologies at 30m depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "imgplot = plt.imshow(to_carto(litho_classes_depth[:,:,dim_z-1]), cmap=cms['cmap'])\n",
    "t = plt.title('Primary lithologies at 1m depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_borehole_data(df):\n",
    "    # We may have something fancy visual down the track, for now, a dataframe subsetting. \n",
    "    px = [p.Time for p in points]\n",
    "    py = [p.CND_011 for p in points]\n",
    "\n",
    "    x_scale, y_scale = LinearScale(), LogScale()\n",
    "    x_scale.allow_padding = False\n",
    "    x_ax = Axis(label='Time (s)', scale=x_scale)\n",
    "    y_ax = Axis(label='CND 011(?)', scale=y_scale, orientation='vertical')\n",
    "\n",
    "    lines = Lines(x=px, y=py, scales={'x': x_scale, 'y': y_scale})\n",
    "\n",
    "    elevation = Figure(title='CND 011 Chart', axes=[x_ax, y_ax], marks=[lines])\n",
    "    elevation.layout.width = 'auto'\n",
    "    elevation.layout.height = 'auto'\n",
    "    elevation.layout.min_height = '500px'\n",
    "\n",
    "    elevation.interaction = IndexSelector(scale=x_scale)\n",
    "\n",
    "    return elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_geo_borehole(geomap, boreholelayer):\n",
    "    \"\"\"\n",
    "    Links the geolocation of the markers to the display of the bvorehole log\n",
    "    Changing the selection on the marker will update the\n",
    "    borehole display\n",
    "    \"\"\"\n",
    "    # add a checkbox to auto center\n",
    "    autocenter = Checkbox(value=False, description='Auto Center')\n",
    "    autocenter_control = WidgetControl(widget=autocenter, position='bottomright')\n",
    "    geomap.add_control(autocenter_control)\n",
    "\n",
    "    brushintsel = geomap.interaction\n",
    "    def update_range(change):\n",
    "        \"\"\"\n",
    "        Update the position on the map when the elevation\n",
    "        graph selector changes\n",
    "        \"\"\"\n",
    "        if brushintsel.selected.shape != (1,):\n",
    "            return\n",
    "        marker.visible = True\n",
    "        selected = brushintsel.selected # time stamp in seconds for a day\n",
    "        point = find_point(selected)\n",
    "        marker.location = (point.Latitude, point.Longitude)\n",
    "        if autocenter.value:\n",
    "            trace.center = marker.location\n",
    "        #position = max(0, int((selected / distance_from_start) * len(points)))\n",
    "    brushintsel.observe(update_range, 'selected')\n",
    "\n",
    "    \n",
    "def link_trace_elevation(trace, elevation, points):\n",
    "    \"\"\"\n",
    "    Link the trace the elevation graph.\n",
    "    Changing the selection on the elevation will update the\n",
    "    marker on the map\n",
    "    \"\"\"\n",
    "    times = np.asarray([p.Time for p in points])\n",
    "\n",
    "    def find_point(time):\n",
    "        \"\"\"\n",
    "        Find a point given the time\n",
    "        \"\"\"\n",
    "        dist_1 = abs(times - time)\n",
    "        pos = np.argmin(dist_1)\n",
    "        return points[pos]\n",
    "    \n",
    "    # add a checkbox to auto center\n",
    "    autocenter = Checkbox(value=False, description='Auto Center')\n",
    "    autocenter_control = WidgetControl(widget=autocenter, position='bottomright')\n",
    "    trace.add_control(autocenter_control)\n",
    "    # mark the current position on the map\n",
    "    start = points[0]\n",
    "    marker = CircleMarker(visible=False, location=(start.Latitude, start.Longitude),\n",
    "                          radius=10, color=\"green\", fill_color=\"green\")\n",
    "    trace.add_layer(marker)\n",
    "    brushintsel = elevation.interaction\n",
    "    def update_range(change):\n",
    "        \"\"\"\n",
    "        Update the position on the map when the elevation\n",
    "        graph selector changes\n",
    "        \"\"\"\n",
    "        if brushintsel.selected.shape != (1,):\n",
    "            return\n",
    "        marker.visible = True\n",
    "        selected = brushintsel.selected # time stamp in seconds for a day\n",
    "        point = find_point(selected)\n",
    "        marker.location = (point.Latitude, point.Longitude)\n",
    "        if autocenter.value:\n",
    "            trace.center = marker.location\n",
    "        #position = max(0, int((selected / distance_from_start) * len(points)))\n",
    "    brushintsel.observe(update_range, 'selected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatSlider\n",
    "interact(slow_function,i=FloatSlider(min=1e5, max=1e7, step=1e5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gpx(points):\n",
    "    trace = plot_map(points)\n",
    "    elevation = plot_elevation(points)\n",
    "    debug = Label(value='')\n",
    "    display(trace)\n",
    "    display(elevation)\n",
    "    display(debug)\n",
    "    link_trace_elevation(trace, elevation, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gpx(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 ELA",
   "language": "python",
   "name": "ela"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
